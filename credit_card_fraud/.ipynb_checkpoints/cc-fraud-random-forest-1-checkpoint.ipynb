{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec61b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367709e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a46f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25817c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df['Class']==1]\n",
    "normal = df[df['Class']==0]\n",
    "\n",
    "print(f\"Shape of Fraudulant transactions: {fraud.shape}\")\n",
    "print(f\"Shape of Non-Fraudulant transactions: {normal.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c39f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class', axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "start = time.time()\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "print(f\"Training time: {(stop - start) * 1000 }ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model, feature_dependence=\"independent\")\n",
    "start = time.time()\n",
    "print(start)\n",
    "shap_values = explainer.shap_values(x_train)\n",
    "stop = time.time()\n",
    "print(stop)\n",
    "\n",
    "print(f\"Training time: {(stop - start) * 1000 }ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "shap.summary_plot(shap_values, x_train, max_display=len(x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf4f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vals= np.abs(shap_values).mean(0)\n",
    "feature_importance = pd.DataFrame(list(zip(x_train.columns, vals)),columns=['feature_name','importance_value'])\n",
    "feature_importance.sort_values(by=['importance_value'],ascending=False,inplace=True)\n",
    "feature_importance.to_csv('./results/random-forest/cc-fraud-shap-random-forest.csv')\n",
    "\n",
    "print(feature_importance.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387251ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "measures_data = []\n",
    "featured_names = []\n",
    "\n",
    "def print_classification_report(classification_report):\n",
    "    accuracy = classification_report[\"accuracy\"]\n",
    "    precision = classification_report[\"weighted avg\"][\"precision\"]\n",
    "    f1_score = classification_report[\"weighted avg\"][\"f1-score\"]\n",
    "    recall = classification_report[\"weighted avg\"][\"recall\"]\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Training time: {(stop - start) * 1000 }s\")\n",
    "\n",
    "def get_measures(feature, classification_report, training_time, shap_value, storage): \n",
    "    accuracy = classification_report[\"accuracy\"]\n",
    "    precision = classification_report[\"weighted avg\"][\"precision\"]\n",
    "    f1_score = classification_report[\"weighted avg\"][\"f1-score\"]\n",
    "    recall = classification_report[\"weighted avg\"][\"recall\"]\n",
    "    \n",
    "    measures_data.append([feature, accuracy, precision, recall, f1_score, training_time, shap_value, storage])\n",
    "\n",
    "def train_model(feature, shap_value):\n",
    "    featured_names.append(feature)\n",
    "    \n",
    "    x = df[featured_names]\n",
    "    y = df.Class\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7)\n",
    "\n",
    "    start = time.time()\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    stop = time.time()\n",
    "    \n",
    "    prediction = model.predict(x_test)\n",
    "\n",
    "    storage = get_storage(featured_names)\n",
    "    training_time = (stop - start) * 1000\n",
    "    classification = classification_report(y_test, prediction, output_dict=True)\n",
    "    get_measures(feature, classification, training_time, shap_value, storage)\n",
    "\n",
    "def get_storage(features):\n",
    "    merged_features = ['Class'] + features\n",
    "    temp = df[merged_features]\n",
    "    temp.to_csv('./dataset/temp.csv')\n",
    "    \n",
    "    return os.stat('./dataset/temp.csv').st_size\n",
    "            \n",
    "def shap_all(df):\n",
    "    for index, row in df.iterrows():\n",
    "        train_model(row['feature_name'], row['importance_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_all(feature_importance)\n",
    "\n",
    "measures_df = pd.DataFrame(measures_data, columns = ['Feature Name', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Training Time', 'Shap Value', 'Storage'])\n",
    "\n",
    "measures_df.to_csv('./results/random-forest/cc-fraud-random-forest-report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33577b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Performance\n",
    "\n",
    "def show_accuracy_chart(df):\n",
    "    temp_1 = df['Accuracy'].tolist()\n",
    "    temp_2 = list(range(1,(len(temp_1) + 1)))\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.plot(temp_2, temp_1)\n",
    "    plt.savefig('./results/random-forest/cc-fraud-random-forest-accuracy.png')\n",
    "\n",
    "def show_precision_chart(df):\n",
    "    temp_1 = df['Precision'].tolist()\n",
    "    temp_2 = list(range(1,(len(temp_1) + 1)))\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Precision (%)\")\n",
    "    plt.plot(temp_2, temp_1)\n",
    "    plt.savefig('./results/random-forest/cc-fraud-random-forest-precision.png')\n",
    "    \n",
    "def show_recall_chart(df):\n",
    "    temp_1 = df['Recall'].tolist()\n",
    "    temp_2 = list(range(1,(len(temp_1) + 1)))\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Recall (%)\")\n",
    "    plt.plot(temp_2, temp_1)\n",
    "    plt.savefig('./results/random-forest/cc-fraud-random-forest-recall.png')\n",
    "    \n",
    "def show_f1_score_chart(df):\n",
    "    temp_1 = df['F1 Score'].tolist()\n",
    "    temp_2 = list(range(1,(len(temp_1) + 1)))\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"F1 Score (%)\")\n",
    "    plt.plot(temp_2, temp_1)\n",
    "    plt.savefig('./results/random-forest/cc-fraud-random-forest-f1-score.png')\n",
    "\n",
    "# Storage\n",
    "    \n",
    "def show_storage_chart(df):\n",
    "    temp_1 = df['Storage'].tolist()\n",
    "    temp_2 = list(range(1,(len(temp_1) + 1)))\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Storage (bytes)\")\n",
    "    plt.plot(temp_2, temp_1)\n",
    "    plt.savefig('./results/random-forest/cc-fraud-random-forest-storage.png')\n",
    "    \n",
    "# Training Time\n",
    "    \n",
    "def show_training_chart(df):\n",
    "    temp_1 = df['Training Time'].tolist()\n",
    "    temp_2 = list(range(1,(len(temp_1) + 1)))\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Time (ms)\")\n",
    "    plt.plot(temp_2, temp_1)\n",
    "    plt.savefig('./results/random-forest/cc-fraud-random-forest-storage.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88598b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy_chart(measures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_precision_chart(measures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b43d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_recall_chart(measures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f347ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_f1_score_chart(measures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c02c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_storage_chart(measures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b04ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_training_chart(measures_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - XAI",
   "language": "python",
   "name": "xai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
